#!/usr/bin/env python3
"""
é£ä¹¦å†™å…¥å™¨ v3 - ç®€åŒ–ç‰ˆæœ¬
ç›´æ¥ä½¿ç”¨ä¼ å…¥çš„table_idï¼Œæ— éœ€ç»´åº¦é…ç½®
"""

import asyncio
import json
import logging
from typing import Dict, List, Optional, Any
from datetime import datetime

try:
    import lark_oapi as lark
    from lark_oapi.api.bitable.v1 import *
except ImportError:
    # æä¾›å…¼å®¹æ€§æç¤º
    raise ImportError("éœ€è¦å®‰è£…é£ä¹¦SDK: pip install lark-oapi")

logger = logging.getLogger(__name__)


class FeishuWriterV3:
    """ç®€åŒ–ç‰ˆé£ä¹¦å†™å…¥å™¨ - ç›´æ¥ä½¿ç”¨table_id"""
    
    def __init__(self, config: dict):
        """
        åˆå§‹åŒ–é£ä¹¦å†™å…¥å™¨
        
        Args:
            config: é…ç½®å­—å…¸ï¼Œå¿…é¡»åŒ…å«table_id
        """
        self.enabled = config.get("enabled", False)
        self.app_id = config.get("app_id", "")
        self.app_secret = config.get("app_secret", "")
        self.app_token = config.get("app_token", "")
        self.table_id = config.get("table_id", "")
        
        # åˆ›å»ºclient
        self.client = lark.Client.builder() \
            .app_id(self.app_id) \
            .app_secret(self.app_secret) \
            .log_level(lark.LogLevel.INFO) \
            .build()
            
        # ç¼“å­˜å­—æ®µæ˜ å°„ï¼šfield_name -> field_info
        self._field_cache: Dict[str, Dict[str, Any]] = {}
        
        # åå‘æ˜ å°„ç¼“å­˜ï¼šè‹±æ–‡é”® -> ä¸­æ–‡å­—æ®µä¿¡æ¯
        self._reverse_mapping_cache: Dict[str, Dict[str, Any]] = {}
        
        # éªŒè¯é…ç½®
        if not all([self.app_id, self.app_secret, self.app_token, self.table_id]):
            self.enabled = False
            logger.warning("[é£ä¹¦] é…ç½®ä¸å®Œæ•´ï¼Œå†™å…¥åŠŸèƒ½å·²ç¦ç”¨ã€‚")
            
    async def get_table_schema(self) -> Dict[str, Dict[str, Any]]:
        """è·å–è¡¨æ ¼çš„å­—æ®µschema"""
        if not self.enabled:
            logger.warning("[é£ä¹¦] åŠŸèƒ½æœªå¯ç”¨ï¼Œæ— æ³•è·å–schemaã€‚")
            return {}
            
        if self._field_cache:
            return self._field_cache
            
        try:
            request: ListAppTableFieldRequest = ListAppTableFieldRequest.builder() \
                .app_token(self.app_token) \
                .table_id(self.table_id) \
                .page_size(200) \
                .build()
                
            response: ListAppTableFieldResponse = self.client.bitable.v1.app_table_field.list(request)
            
            if not response.success():
                logger.error(f"[é£ä¹¦] è·å–å­—æ®µåˆ—è¡¨å¤±è´¥ï¼Œcode: {response.code}, msg: {response.msg}")
                return {}
                
            # è§£æå­—æ®µä¿¡æ¯
            schema = {}
            if response.data and response.data.items:
                for field in response.data.items:
                    schema[field.field_name] = {
                        "id": field.field_id,
                        "type": field.type,
                        "ui_type": field.ui_type,
                        "property": field.property or {}
                    }
                    
            self._field_cache = schema
            logger.info(f"[é£ä¹¦] è·å–åˆ° {len(schema)} ä¸ªå­—æ®µ")
            return schema
            
        except Exception as e:
            logger.error(f"[é£ä¹¦] è·å–schemaæ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return {}
            
    def _build_reverse_mapping(self, schema: Dict[str, Dict[str, Any]]) -> Dict[str, Dict[str, Any]]:
        """æ„å»ºè‹±æ–‡åˆ°ä¸­æ–‡çš„åå‘æ˜ å°„"""
        if not schema:
            return {}
            
        # ä»data_processor.pyå¯¼å…¥æ˜ å°„è¡¨
        try:
            from data_processor import FIELD_EN_MAP
            reverse_map = {}
            
            # è°ƒè¯•ä¿¡æ¯ï¼šæ˜¾ç¤ºschemaä¸­çš„å­—æ®µå
            logger.info(f"[é£ä¹¦] Schemaå­—æ®µ: {list(schema.keys())[:10]}...")
            logger.info(f"[é£ä¹¦] FIELD_EN_MAP: {list(FIELD_EN_MAP.items())[:5]}...")
            
            # æ„å»ºæ ‡å‡†åŒ–æ˜ å°„ï¼šå¤„ç†ç©ºæ ¼å’Œç‰¹æ®Šå­—ç¬¦
            def normalize_field_name(name: str) -> str:
                """æ›´æ™ºèƒ½çš„æ ‡å‡†åŒ–ï¼šå¤„ç†æ‰€æœ‰å¯èƒ½çš„å˜ä½“"""
                import re
                # å¤„ç†ç©ºæ ¼
                name = re.sub(r'\s+', '', name)
                # å¤„ç†æ‹¬å·
                name = name.replace('ï¼ˆ', '(').replace('ï¼‰', ')')
                # å¤„ç†æ–œæ å·®å¼‚ï¼š| -> /
                name = name.replace('|', '/')
                # å¤„ç†åŠ å·å·®å¼‚ï¼šâ• -> +
                name = name.replace('â•', '+')
                # å¤„ç†ç‰¹æ®Šå­—ç¬¦
                name = re.sub(r'[^\w\(\)\+/\-]', '', name)
                return name
            
            # åˆ›å»ºschemaçš„æ ‡å‡†åŒ–ç´¢å¼•
            normalized_schema = {normalize_field_name(k): (k, v) for k, v in schema.items()}
            
            # åˆ›å»ºåå‘æ˜ å°„ï¼šè‹±æ–‡é”® -> ä¸­æ–‡å­—æ®µä¿¡æ¯
            matched_count = 0
            failed_mappings = []
            
            for cn_name, en_name in FIELD_EN_MAP.items():
                normalized_cn = normalize_field_name(cn_name)
                
                if normalized_cn in normalized_schema:
                    original_cn, field_info = normalized_schema[normalized_cn]
                    reverse_map[en_name] = field_info
                    matched_count += 1
                    logger.debug(f"[é£ä¹¦] æ˜ å°„æˆåŠŸ: {en_name} -> {original_cn} -> {field_info['id']}")
                elif cn_name in schema:
                    # ç›´æ¥åŒ¹é…ï¼ˆå…¼å®¹æ—§æ ¼å¼ï¼‰
                    reverse_map[en_name] = schema[cn_name]
                    matched_count += 1
                    logger.debug(f"[é£ä¹¦] ç›´æ¥åŒ¹é…: {en_name} -> {cn_name} -> {schema[cn_name]['id']}")
                else:
                    failed_mappings.append((cn_name, en_name))
                    logger.debug(f"[é£ä¹¦] æœªæ‰¾åˆ°ä¸­æ–‡å­—æ®µ: {cn_name} (æ ‡å‡†åŒ–: {normalized_cn})")
            
            # æŠ¥å‘Šæ˜ å°„ç»“æœ
            logger.info(f"[é£ä¹¦] æ„å»ºåå‘æ˜ å°„ï¼šå…± {len(FIELD_EN_MAP)} ä¸ªæ˜ å°„ï¼ŒæˆåŠŸåŒ¹é… {matched_count} ä¸ªå­—æ®µ")
            
            if failed_mappings:
                logger.warning(f"[é£ä¹¦] æ˜ å°„å¤±è´¥çš„å­—æ®µ: {failed_mappings[:10]}")
                
                # æ˜¾ç¤ºschemaä¸­å¯ç”¨çš„ä¸­æ–‡å­—æ®µ
                chinese_fields = [k for k in schema.keys() if any('\u4e00' <= c <= '\u9fff' for c in k)]
                logger.info(f"[é£ä¹¦] å¯ç”¨çš„ä¸­æ–‡å­—æ®µ: {chinese_fields}")
            
            # æ˜¾ç¤ºå‰10ä¸ªæˆåŠŸæ˜ å°„
            if reverse_map:
                sample = dict(list(reverse_map.items())[:10])
                logger.info(f"[é£ä¹¦] åå‘æ˜ å°„ç¤ºä¾‹: {sample}")
            
            return reverse_map
            
        except ImportError:
            logger.warning("[é£ä¹¦] æ— æ³•å¯¼å…¥FIELD_EN_MAPï¼Œä½¿ç”¨ç©ºæ˜ å°„")
            return {}

    def _process_value_by_type(self, value: Any, field_info: Dict[str, Any]) -> Any:
        """æ ¹æ®å­—æ®µç±»å‹å¤„ç†å€¼ - åªåšç±»å‹è½¬æ¢ï¼Œä¸åšæ¸…æ´—"""
        ui_type = field_info.get("ui_type", "")
        
        # æ­¤æ—¶valueå·²ç»æ˜¯å¹²å‡€æ•°æ®ï¼Œåªéœ€ç±»å‹è½¬æ¢
        if ui_type == "Text":
            return str(value)
        elif ui_type == "Number":
            return float(value)
        elif ui_type == "DateTime":
            if isinstance(value, int):
                return value
            dt = datetime.fromisoformat(str(value).replace('Z', '+00:00'))
            return int(dt.timestamp() * 1000)
        elif ui_type == "Checkbox":
            return bool(value)
        elif ui_type == "SingleSelect":
            return {"id": str(value)}
        elif ui_type == "MultiSelect":
            return [{"id": str(v)} for v in value] if isinstance(value, list) else [{"id": str(value)}]
        else:
            return str(value)
            
    def _has_meaningful_value(self, v: Any) -> bool:
        """True if value is not None and not empty string after strip; 0 is meaningful."""
        if v is None:
            return False
        if isinstance(v, str) and v.strip() == "":
            return False
        return True
            
    async def write_records(self, records: List[Dict[str, Any]]) -> bool:
        """å†™å…¥è®°å½•åˆ°é£ä¹¦å¤šç»´è¡¨æ ¼ - åªåšå†™å…¥ï¼Œä¸åšæ¸…æ´—"""
        if not self.enabled:
            logger.info("[é£ä¹¦] å†™å…¥æœªå¯ç”¨ï¼Œè·³è¿‡å†™å…¥ã€‚")
            return True
            
        if not records:
            logger.info("[é£ä¹¦] æ²¡æœ‰è®°å½•å¯å†™å…¥ã€‚")
            return True
            
        try:
            logger.info(f"[é£ä¹¦] å¼€å§‹å†™å…¥ï¼Œå…± {len(records)} æ¡è®°å½•")
            
            # è·å–è¡¨æ ¼schema
            schema = await self.get_table_schema()
            if not schema:
                logger.error("[é£ä¹¦] æ— æ³•è·å–è¡¨æ ¼schema")
                return False
                
            # æ„å»ºåå‘æ˜ å°„
            reverse_mapping = self._build_reverse_mapping(schema)
            
            # ğŸ” æ˜ å°„éªŒè¯æ¢é’ˆï¼šæ˜¾ç¤ºæœªæ˜ å°„çš„å­—æ®µ
            if records:
                first_record_keys = set(records[0].keys())
                mapped_keys = set(reverse_mapping.keys())
                unmapped_keys = first_record_keys - mapped_keys
                if unmapped_keys:
                    logger.warning(f"ğŸ” æœªæ˜ å°„å­—æ®µ: {list(unmapped_keys)[:5]}{'...' if len(unmapped_keys) > 5 else ''}")
                    logger.info(f"ğŸ” å·²æ˜ å°„å­—æ®µç¤ºä¾‹: {dict(list(reverse_mapping.items())[:3])}")
            
            # æ„å»ºå†™å…¥æ•°æ®
            table_records = []
            
            for record in records:
                fields_data = {}
                
                for field_name, value in record.items():
                    if value is None:  # å¹²å‡€æ•°æ®ï¼Œç›´æ¥è·³è¿‡None
                        continue
                        
                    field_info = reverse_mapping.get(field_name)
                    if field_info:
                        processed_value = self._process_value_by_type(value, field_info)
                        if processed_value is not None:
                            fields_data[field_info["id"]] = processed_value
                
                if fields_data:  # åªæœ‰æœ‰æ•ˆæ•°æ®æ‰å†™å…¥
                    table_records.append(
                        AppTableRecord.builder()
                        .fields(fields_data)
                        .build()
                    )
                    
            if not table_records:
                logger.warning("[é£ä¹¦] æ²¡æœ‰æœ‰æ•ˆè®°å½•å¯ä»¥å†™å…¥")
                return False
                
            # åˆ†æ‰¹å¤„ç†
            batch_size = 500
            total_success = 0
            total_total = len(table_records)
            
            for i in range(0, len(table_records), batch_size):
                batch = table_records[i:i+batch_size]
                
                # ğŸ” ç²¾ç®€æ¢é’ˆï¼šåªæ‰“å°å…³é”®ä¿¡æ¯
                if len(batch) > 0:
                    first_record = batch[0]
                    if hasattr(first_record, '_fields') and first_record._fields:
                        field_summary = []
                        for field_id, value in first_record._fields.items():
                            # åå‘æŸ¥æ‰¾å­—æ®µå
                            field_name = None
                            for cn_name, info in schema.items():
                                if info.get('id') == field_id:
                                    field_name = cn_name
                                    break
                            field_summary.append(f"{field_name or field_id}({field_id})={value}[{type(value).__name__}]")
                        
                        logger.info(f"ğŸ” æ‰¹æ¬¡{i//batch_size + 1}æ ·æœ¬: {', '.join(field_summary[:3])}{'...' if len(field_summary) > 3 else ''}")
                
                request: BatchCreateAppTableRecordRequest = BatchCreateAppTableRecordRequest.builder() \
                    .app_token(self.app_token) \
                    .table_id(self.table_id) \
                    .request_body(BatchCreateAppTableRecordRequestBody.builder()
                        .records(batch)
                        .build()) \
                    .build()
                    
                response: BatchCreateAppTableRecordResponse = self.client.bitable.v1.app_table_record.batch_create(request)
                
                if response.success():
                    batch_success = len(response.data.records) if response.data else 0
                    total_success += batch_success
                    logger.info(f"[é£ä¹¦] æ‰¹æ¬¡ {i//batch_size + 1} æˆåŠŸå†™å…¥ {batch_success}/{len(batch)} æ¡è®°å½•")
                else:
                    logger.error(f"[é£ä¹¦] æ‰¹æ¬¡ {i//batch_size + 1} å†™å…¥å¤±è´¥: code={response.code}, msg={response.msg}")
                    
            logger.info(f"[é£ä¹¦] å†™å…¥å®Œæˆ: æˆåŠŸ {total_success}/{total_total} æ¡è®°å½•")
            return total_success == total_total
            
        except Exception as e:
            logger.error(f"[é£ä¹¦] å†™å…¥æ—¶å‘ç”Ÿé”™è¯¯: {e}")
            return False
            
    async def validate_config(self) -> Dict[str, Any]:
        """éªŒè¯é…ç½®å’Œè¡¨æ ¼ç»“æ„"""
        result = {
            "enabled": self.enabled,
            "table_id": self.table_id,
            "valid": True,
            "errors": []
        }
        
        if not self.enabled:
            result["valid"] = False
            result["errors"].append("é£ä¹¦åŠŸèƒ½æœªå¯ç”¨")
            return result
            
        if not all([self.app_id, self.app_secret, self.app_token, self.table_id]):
            result["valid"] = False
            result["errors"].append("é£ä¹¦é…ç½®ä¸å®Œæ•´")
            return result
            
        try:
            schema = await self.get_table_schema()
            if not schema:
                result["valid"] = False
                result["errors"].append("æ— æ³•è·å–è¡¨æ ¼schema")
            else:
                result["field_count"] = len(schema)
                result["fields"] = list(schema.keys())
                
                # æµ‹è¯•åå‘æ˜ å°„
                reverse_mapping = self._build_reverse_mapping(schema)
                result["mapped_fields"] = len(reverse_mapping)
                result["sample_mapping"] = dict(list(reverse_mapping.items())[:5])
                
                # ğŸ” å¢å¼ºéªŒè¯ï¼šæ˜¾ç¤ºè¯¦ç»†çš„å­—æ®µæ˜ å°„æŠ¥å‘Š
                try:
                    from data_processor import FIELD_EN_MAP
                    
                    # åˆ›å»ºè¯¦ç»†çš„æ˜ å°„æŠ¥å‘Š
                    mapping_report = []
                    for cn_name, en_name in FIELD_EN_MAP.items():
                        if cn_name in schema:
                            field_info = schema[cn_name]
                            mapping_report.append({
                                "chinese": cn_name,
                                "english": en_name,
                                "field_id": field_info.get('id'),
                                "type": field_info.get('ui_type'),
                                "status": "âœ… åŒ¹é…æˆåŠŸ"
                            })
                        else:
                            mapping_report.append({
                                "chinese": cn_name,
                                "english": en_name,
                                "field_id": None,
                                "type": None,
                                "status": "âŒ æœªæ‰¾åˆ°"
                            })
                    
                    result["mapping_report"] = mapping_report
                    result["mapping_success_rate"] = f"{len([m for m in mapping_report if m['status'] == 'âœ… åŒ¹é…æˆåŠŸ'])}/{len(mapping_report)}"
                    
                    # æ˜¾ç¤ºå­—æ®µç±»å‹åˆ†æ
                    field_types = {}
                    for cn_name, info in schema.items():
                        field_type = info.get('ui_type', 'unknown')
                        if field_type not in field_types:
                            field_types[field_type] = []
                        field_types[field_type].append(cn_name)
                    
                    result["field_types"] = {k: len(v) for k, v in field_types.items()}
                    
                    # æ˜¾ç¤ºè¡¨æ ¼åŸºæœ¬ä¿¡æ¯
                    logger.info(f"ğŸ” è¡¨æ ¼éªŒè¯ç»“æœ:")
                    logger.info(f"   è¡¨æ ¼ID: {self.table_id}")
                    logger.info(f"   æ€»å­—æ®µæ•°: {len(schema)}")
                    logger.info(f"   æ˜ å°„æˆåŠŸç‡: {result['mapping_success_rate']}")
                    logger.info(f"   å­—æ®µç±»å‹åˆ†å¸ƒ: {result['field_types']}")
                    
                    # æ˜¾ç¤ºå‰10ä¸ªæœªæ˜ å°„å­—æ®µ
                    missing_fields = [m for m in mapping_report if m['status'] == 'âŒ æœªæ‰¾åˆ°']
                    if missing_fields:
                        logger.warning(f"ğŸ” æœªæ˜ å°„å­—æ®µ(å‰10ä¸ª):")
                        for field in missing_fields[:10]:
                            logger.warning(f"   {field['chinese']} -> {field['english']}")
                    
                except ImportError:
                    logger.warning("[é£ä¹¦éªŒè¯] æ— æ³•å¯¼å…¥FIELD_EN_MAPç”¨äºéªŒè¯")
                
        except Exception as e:
            result["valid"] = False
            result["errors"].append(str(e))
            
        return result